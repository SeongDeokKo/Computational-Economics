{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM6dVkps8Wqvt/oGvj4v+Mt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongDeokKo/Computational-Economics/blob/main/Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFQAaPGIzHVH",
        "outputId": "b08b038e-35af-4bde-c12d-03377a658a1e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wcZuU653ZS"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/')\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "import FunLib_stock as FL\n",
        "import multiprocessing as mp"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzL2d8oc1S6H"
      },
      "source": [
        "new_firm_data = pd.read_csv('/content/drive/MyDrive/x_y_wo_inter.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC_H-R8b3qX_"
      },
      "source": [
        "new_firm_data[new_firm_data.columns[2:96]] = new_firm_data[new_firm_data.columns[2:96]].astype('float32')\n",
        "new_firm_data[new_firm_data.columns[0:2]] = new_firm_data[new_firm_data.columns[0:2]].astype('int32')\n",
        "new_firm_data[new_firm_data.columns[96:170]] = new_firm_data[new_firm_data.columns[96:170]].astype('int8')\n",
        "new_firm_data[new_firm_data.columns[170]] = new_firm_data[new_firm_data.columns[170]].astype('float32')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWVWPG661S81"
      },
      "source": [
        "\n",
        "def R2OOS(y_true, y_forecast):\n",
        "    \n",
        "    import numpy as np\n",
        "   \n",
        "    SSres = np.nansum(np.square(y_true-y_forecast))\n",
        "    SStot = np.nansum(np.square(y_true))\n",
        "\n",
        "    return 1-SSres/SStot\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PCR, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pca_regression(X,Y,numpc,num_t_v):\n",
        "    # numpc (list) : # of principal component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of component \n",
        "    mse = np.full((len(numpc),1),np.nan)\n",
        "\n",
        "    for i in range(len(numpc)):\n",
        "        pca = PCA(n_components = numpc[i])\n",
        "        principalComponents = pca.fit_transform(X_train_scaled)\n",
        "        \n",
        "        X_val_weighted = pca.transform(X_val_scaled)\n",
        "        \n",
        "        line_fitter = LinearRegression()\n",
        "        line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "        Ypred_val = np.full((num_val,1),np.nan, dtype = np.float32)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0] = line_fitter.predict(X_val_weighted[j,:].reshape(1,-1))\n",
        "                   \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpc = numpc[np.argmin(mse)]\n",
        "    \n",
        "    pca = PCA(n_components = argmin_numpc)\n",
        "    principalComponents = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    X_test_weighted = pca.transform(X_test_scaled)\n",
        "    \n",
        "    line_fitter = LinearRegression()\n",
        "    line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "    Ypred_test = np.full((num_test,1),np.nan, dtype = np.float32)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=line_fitter.predict(X_test_weighted[j,:].reshape(1,-1))\n",
        "        \n",
        "          \n",
        "    return Ypred_test, argmin_numpc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PLS, 94 + dummy variable(no intersection term), Use cross-validation to select the number of components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pls_regression(X,Y,numpls,num_t_v):\n",
        "    # numpls (list) : # of component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.cross_decomposition import PLSRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of component \n",
        "    mse = np.full((len(numpls),1),np.nan)\n",
        "\n",
        "    for i in range(len(numpls)):\n",
        "        pls = PLSRegression(n_components = numpls[i])\n",
        "        pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0]=pls.predict(X_val_scaled[j,:].reshape(1,-1))          \n",
        "        \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpls = numpls[np.argmin(mse)]\n",
        "    \n",
        "    pls = PLSRegression(n_components = argmin_numpls)\n",
        "    pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=pls.predict(X_test_scaled[j,:].reshape(1,-1))          \n",
        "              \n",
        "    \n",
        "    return Ypred_test, argmin_numpls\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLl0g57O1S_g"
      },
      "source": [
        "\n",
        "# =========================================================================\n",
        "#  elastic-net, Loss : mse + penalty, 94 + dummy variable(no intersection term), hyperparameter tuning\n",
        "# ========================================================================= \n",
        "\n",
        "def elastic_net(X,Y,num_t_v):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import ElasticNetCV\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:(num_train+num_val),:]   # train + validation\n",
        "    Y_train = Y[:(num_train+num_val),:]   # train + validation\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    # pre-define validation \n",
        "    test_fold =  np.concatenate(((np.full((num_train),-1),np.full((num_val),0))))\n",
        "    ps = PredefinedSplit(test_fold.tolist())\n",
        "    \n",
        "    # fit & predict \n",
        "    model = ElasticNetCV(cv=ps, max_iter=5000, n_jobs=-1, l1_ratio=[.1, .3, .5, .7, .9], \n",
        "                         random_state=42)\n",
        "    model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "    \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=model.predict(X_test_scaled[j,:].reshape(1,-1))\n",
        "        \n",
        "    \n",
        "    return Ypred_test\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   Generalized-linear, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "# Loss ftn : MSE\n",
        "# We use Lasso (Not group Lass) \n",
        "# include spline series of order 2 \n",
        "# number of knots = [3,5,7...] and we choose the only one that minimize cross-validation MSE \n",
        "# we set knots by using linspace(col.mean-2*col.std, col.mean+2*col.std, # knots)\n",
        "# for example if we use 3 knots, the # of variables is 94(order1) + 94*3(order 2) + dummy(74) = 450 \n",
        "\n",
        "def general_linear(X,Y,num_t_v, num_knots):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    from sklearn.linear_model import LassoCV\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "       \n",
        "    mse = np.full((len(num_knots),1),np.nan)\n",
        "    Ypred_test = np.full((len(num_knots),num_test,1),np.nan)\n",
        "    \n",
        "    for i in range(len(num_knots)):\n",
        "        \n",
        "        X_temp = X\n",
        "        \n",
        "        # 94 variables > make spline series of order 2\n",
        "        for j in range(94):\n",
        "            \n",
        "            # make knots\n",
        "            std_train = np.std(X[:num_train,j])\n",
        "            mean_train = np.mean(X[:num_train,j])           \n",
        "            \n",
        "            knots = np.linspace(mean_train-2*std_train, mean_train+2*std_train, num_knots[i])\n",
        "            \n",
        "            # add (variable - knots)**2 column\n",
        "            for k in knots:\n",
        "                add_col = ((X[:,j]-k)**2).reshape(-1,1)\n",
        "                X_temp = np.concatenate((X_temp, add_col), axis=1)\n",
        "        \n",
        "        print(X_temp.shape)\n",
        "        \n",
        "        # Split data into training and test\n",
        "        X_train = X_temp[:(num_train+num_val),:]   # train + validation\n",
        "        Y_train = Y[:(num_train+num_val),:]   # train + validation\n",
        "        \n",
        "        X_test = X_temp[(num_train+num_val):,:]\n",
        "        \n",
        "        # Scale Inputs for Training\n",
        "        X_scaler = StandardScaler()\n",
        "        X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "        \n",
        "        X_test_scaled = X_scaler.transform(X_test)\n",
        "        \n",
        "        # pre-define validation \n",
        "        test_fold =  np.concatenate(((np.full((num_train),-1),np.full((num_val),0))))\n",
        "        ps = PredefinedSplit(test_fold.tolist())\n",
        "        \n",
        "        # we use cross-val to find best 'alpha'(penalty term in loss function)\n",
        "        model = LassoCV(cv=ps, max_iter=10000, n_jobs=-1, random_state= 50)\n",
        "        model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "\n",
        "        \n",
        "        # to choose # of knots, calculate mse of validation set\n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0]=model.predict(X_train_scaled[num_train+j,:].reshape(1,-1))\n",
        "            \n",
        "        mse[i,0] = mean_squared_error(Y[num_train:(num_train+num_val),:].reshape(-1), Ypred_val.reshape(-1))\n",
        "        \n",
        "        # predic test set \n",
        "        for j in range(num_test):\n",
        "            Ypred_test[i,j,0]=model.predict(X_test_scaled[j,:].reshape(1,-1))\n",
        "    \n",
        "     \n",
        "    # choose knots that minimize mse in validation\n",
        "    argmin_index = np.argmin(mse)\n",
        "    \n",
        "    print(argmin_index)\n",
        "    \n",
        "    Ypred_test_final = Ypred_test[argmin_index,:,:].reshape(-1,1)\n",
        "    \n",
        "    return Ypred_test_final\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "716cUGgA4r4C"
      },
      "source": [
        "date_col = new_firm_data['DATE']\n",
        "result = Counter(date_col)\n",
        "date = list(result.keys())\n",
        "num = list(result.values())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMA-8o05KHS"
      },
      "source": [
        "# X_no_inter (168) : 195703 ~ 201612, y(1) :195704 ~ 201701\n",
        "# X-195703 & y-195704 are in the same row. \n",
        "\n",
        "X_no_inter = new_firm_data.iloc[:,2:170]     # without intersect terms\n",
        "y = new_firm_data.iloc[:,-1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgZby-t5fbK"
      },
      "source": [
        "\n",
        "num_est = 1  # We estimate parameter 1 time, here not use\n",
        "\n",
        "# if we estimate parameters more than 1 time(i.e using longer data), we should set below # recursively\n",
        "# Train \n",
        "# Validation \n",
        "# Test \n",
        "num_train = sum(num[84:(216+12*5)])\n",
        "num_val = sum(num[(216+12*5):(216+144+60)])\n",
        "num_test = sum(num[(216+144+60):])\n",
        "num_t_v = [num_train, num_val]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiK2HFY03BFd"
      },
      "source": [
        "y_true = y.iloc[-num_test:].to_numpy().reshape(-1,1)  # for caluclating R2oos"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxcaHYHS3BDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d660a6-9b5b-4dfa-e84f-fbe92d767fc2"
      },
      "source": [
        "\n",
        "# Computational Ressources: Determine Number of available cores\n",
        "ncpus = mp.cpu_count()\n",
        "print(\"CPU count is: \"+str(ncpus))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU count is: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s45KuUSF4VEh",
        "outputId": "9d27b3d5-9885-4898-ac8a-d91152dddb72"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train_ols = X_no_inter.iloc[:(num_train+num_val),:].to_numpy()\n",
        "y_train_ols = y.iloc[:(num_train+num_val)].to_numpy()\n",
        "\n",
        "reg = LinearRegression().fit(X_train_ols, y_train_ols)\n",
        "\n",
        "Y_pred_ols = np.full((num_test,1),np.nan, dtype = np.float32 )\n",
        "\n",
        "for i in range(num_test):\n",
        "    Y_pred_ols[i,0] = reg.predict(X_no_inter.iloc[(num_train+num_val+i),:].to_numpy().reshape(1,-1))\n",
        "    \n",
        "print('R2OOS, MSE error - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols))    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, MSE error - Linear regression without intersection terms :  -0.01913928985595703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnlKgsBI4VG4",
        "outputId": "9c36cdef-ba12-457f-e73b-5dcc5ddfdc54"
      },
      "source": [
        "\n",
        "\n",
        "# ===========================================================================\n",
        "#     OLS, Loss: Huber Loss, 94 + dummy variable(no intersection term)\n",
        "# ===========================================================================\n",
        "\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "reg_huber = HuberRegressor(max_iter=500, alpha=0).fit(X_train_ols, y_train_ols)\n",
        "\n",
        "Y_pred_ols_huber = np.full((num_test,1),np.nan, dtype = np.float32 )\n",
        "\n",
        "for i in range(num_test):\n",
        "    Y_pred_ols_huber[i,0] = reg_huber.predict(X_no_inter.iloc[(num_train+num_val+i),:].to_numpy().reshape(1,-1))\n",
        "\n",
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols_huber))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  -0.0006206035614013672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhYc9PhFrgey"
      },
      "source": [
        "NX = X_no_inter.iloc[109501:,:] \n",
        "NY = y.iloc[109501:]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWMrp_IG4VJX",
        "outputId": "1f75790a-859f-4aa5-b69b-65bcc7f0d8d0"
      },
      "source": [
        "\n",
        "# ===========================================================================\n",
        "#    PCR, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components\n",
        "# ===========================================================================\n",
        "\n",
        "numpc =[3,4,5,10,20,25]\n",
        "\n",
        "\n",
        "Y_pred_pca, argmin_numpc = FL.Pca_regression(NX.to_numpy(), NY.to_numpy().reshape(-1,1), numpc, num_t_v)\n",
        "\n",
        "print('R2OOS, Principal Components Regression - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pca)) \n",
        "print('# of principal components : ', argmin_numpc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Principal Components Regression - without intersection terms :  -0.015273094177246094\n",
            "# of principal components :  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnjnEOPvJfgm",
        "outputId": "cf89997d-183b-4afc-b88b-61a94498e548"
      },
      "source": [
        "\n",
        "# ===========================================================================\n",
        "#    PLS, 94 + dummy variable(no intersection term), Use cross-validation to select the number of components\n",
        "# ===========================================================================\n",
        "\n",
        "numpls = [3,4,5,10,20,25]\n",
        "\n",
        "Y_pred_pls, argmin_numpls = FL.Pls_regression(NX.to_numpy(), NY.to_numpy().reshape(-1,1), numpls, num_t_v)\n",
        "\n",
        "print('R2OOS, Partial Least Square - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pls)) \n",
        "print('# of components : ', argmin_numpls)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Partial Least Square - without intersection terms :  -1.157390536072052\n",
            "# of components :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p46nmR_6JfjO",
        "outputId": "47446014-5798-4581-a05d-a67e6eebe4cb"
      },
      "source": [
        "Y_pred_pls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.09239537],\n",
              "       [ 0.12443741],\n",
              "       [ 0.11558041],\n",
              "       ...,\n",
              "       [ 0.0182573 ],\n",
              "       [ 0.81252609],\n",
              "       [-0.00791839]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MO5Bx2NJflp",
        "outputId": "1f63d066-1a83-4187-b463-8b3d931126aa"
      },
      "source": [
        "\n",
        "# =========================================================================\n",
        "#  elastic-net, Loss : mse + penalty, 94 + dummy variable(no intersection term), hyperparameter tuning\n",
        "# =========================================================================\n",
        "\n",
        "Y_pred_elastic = FL.elastic_net(NX.to_numpy(), NY.to_numpy().reshape(-1,1), num_t_v)\n",
        "\n",
        "print('R2OOS, Elastic-net - without intersection terms : ', FL.R2OOS(y_true, Y_pred_elastic))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Elastic-net - without intersection terms :  0.0024675253993113877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMH28UwfPNRK",
        "outputId": "740f9085-c5af-4462-94d9-7bbb12c353e1"
      },
      "source": [
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   Generalized-linear, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "# Loss ftn : MSE\n",
        "# We use Lasso (Not group Lass) \n",
        "# include spline series of order 2 \n",
        "# number of knots = [3,5,7...] and we choose the only one that minimize cross-validation MSE \n",
        "# we set knots by using linspace(col.mean-2*col.std, col.mean+2*col.std, # knots)\n",
        "# for example if we use 3 knots, the # of variables is 94(order1) + 94*3(order 2) + dummy(74) = 450 \n",
        "\n",
        "num_knots = [3]\n",
        "\n",
        "Y_pred_general_lin = general_linear(NX.to_numpy(), NY.to_numpy().reshape(-1,1), num_t_v, num_knots)\n",
        "\n",
        "print('R2OOS, generalized linear - without intersection terms / with knots : ', FL.R2OOS(y_true, Y_pred_general_lin))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600408, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKbhSPd2TX6D",
        "outputId": "9deb2dcb-482a-4cc7-9a54-4263c03ee5f1"
      },
      "source": [
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols_huber))\n",
        "print('R2OOS, Principal Components Regression - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pca)) \n",
        "print('R2OOS, Partial Least Square - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pls)) \n",
        "print('R2OOS, Elastic-net - without intersection terms : ', FL.R2OOS(y_true, Y_pred_elastic))\n",
        "print('R2OOS, generalized linear - without intersection terms / with knots : ', FL.R2OOS(y_true, Y_pred_general_lin))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  -0.0006206035614013672\n",
            "R2OOS, Principal Components Regression - without intersection terms :  -0.015273094177246094\n",
            "R2OOS, Partial Least Square - without intersection terms :  -1.157390536072052\n",
            "R2OOS, Elastic-net - without intersection terms :  0.0024675253993113877\n",
            "R2OOS, generalized linear - without intersection terms / with knots :  0.001908131940232649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbBzTimvGvDD",
        "outputId": "6ec399f0-e8ac-4023-8705-91b0bd42188f"
      },
      "source": [
        "Y_pred_general_lin"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00608327],\n",
              "       [0.00608327],\n",
              "       [0.00608327],\n",
              "       ...,\n",
              "       [0.00608327],\n",
              "       [0.00608327],\n",
              "       [0.00608327]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEPXBqO5GvFR",
        "outputId": "00fd8064-5b17-4ff4-f799-a282607c17a3"
      },
      "source": [
        "Y_pred_elastic"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00522649],\n",
              "       [0.00624618],\n",
              "       [0.00636093],\n",
              "       ...,\n",
              "       [0.00365887],\n",
              "       [0.0046813 ],\n",
              "       [0.0039413 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}