{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPukYxALBB/6PDQ0B+7XuTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongDeokKo/Computational-Economics/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFQAaPGIzHVH",
        "outputId": "0632a1d9-e260-4a80-cc97-59afbc678c82"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wcZuU653ZS"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/')\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "import FunLib_stock as FL\n",
        "import multiprocessing as mp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzL2d8oc1S6H"
      },
      "source": [
        "new_firm_data = pd.read_csv('/content/drive/MyDrive/x_y_wo_inter.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC_H-R8b3qX_"
      },
      "source": [
        "new_firm_data[new_firm_data.columns[2:96]] = new_firm_data[new_firm_data.columns[2:96]].astype('float32')\n",
        "new_firm_data[new_firm_data.columns[0:2]] = new_firm_data[new_firm_data.columns[0:2]].astype('int32')\n",
        "new_firm_data[new_firm_data.columns[96:170]] = new_firm_data[new_firm_data.columns[96:170]].astype('int8')\n",
        "new_firm_data[new_firm_data.columns[170]] = new_firm_data[new_firm_data.columns[170]].astype('float32')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWVWPG661S81"
      },
      "source": [
        "\n",
        "def R2OOS(y_true, y_forecast):\n",
        "    \n",
        "    import numpy as np\n",
        "   \n",
        "    SSres = np.nansum(np.square(y_true-y_forecast))\n",
        "    SStot = np.nansum(np.square(y_true))\n",
        "\n",
        "    return 1-SSres/SStot\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PCR, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pca_regression(X,Y,numpc,num_t_v):\n",
        "    # numpc (list) : # of principal component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of component \n",
        "    mse = np.full((len(numpc),1),np.nan)\n",
        "\n",
        "    for i in range(len(numpc)):\n",
        "        pca = PCA(n_components = numpc[i])\n",
        "        principalComponents = pca.fit_transform(X_train_scaled)\n",
        "        \n",
        "        X_val_weighted = pca.transform(X_val_scaled)\n",
        "        \n",
        "        line_fitter = LinearRegression()\n",
        "        line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "        Ypred_val = np.full((num_val,1),np.nan, dtype = np.float32)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0] = line_fitter.predict(X_val_weighted[j,:].reshape(1,-1))\n",
        "                   \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpc = numpc[np.argmin(mse)]\n",
        "    \n",
        "    pca = PCA(n_components = argmin_numpc)\n",
        "    principalComponents = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    X_test_weighted = pca.transform(X_test_scaled)\n",
        "    \n",
        "    line_fitter = LinearRegression()\n",
        "    line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "    Ypred_test = np.full((num_test,1),np.nan, dtype = np.float32)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=line_fitter.predict(X_test_weighted[j,:].reshape(1,-1))\n",
        "        \n",
        "          \n",
        "    return Ypred_test, argmin_numpc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PLS, 94 + dummy variable(no intersection term), Use cross-validation to select the number of components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pls_regression(X,Y,numpls,num_t_v):\n",
        "    # numpls (list) : # of component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.cross_decomposition import PLSRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of component \n",
        "    mse = np.full((len(numpls),1),np.nan)\n",
        "\n",
        "    for i in range(len(numpls)):\n",
        "        pls = PLSRegression(n_components = numpls[i])\n",
        "        pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0]=pls.predict(X_val_scaled[j,:].reshape(1,-1))          \n",
        "        \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpls = numpls[np.argmin(mse)]\n",
        "    \n",
        "    pls = PLSRegression(n_components = argmin_numpls)\n",
        "    pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=pls.predict(X_test_scaled[j,:].reshape(1,-1))          \n",
        "              \n",
        "    \n",
        "    return Ypred_test, argmin_numpls\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLl0g57O1S_g"
      },
      "source": [
        "\n",
        "# =========================================================================\n",
        "#  elastic-net, Loss : mse + penalty, 94 + dummy variable(no intersection term), hyperparameter tuning\n",
        "# ========================================================================= \n",
        "\n",
        "def elastic_net(X,Y,num_t_v):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import ElasticNetCV\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:(num_train+num_val),:]   # train + validation\n",
        "    Y_train = Y[:(num_train+num_val),:]   # train + validation\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    # pre-define validation \n",
        "    test_fold =  np.concatenate(((np.full((num_train),-1),np.full((num_val),0))))\n",
        "    ps = PredefinedSplit(test_fold.tolist())\n",
        "    \n",
        "    # fit & predict \n",
        "    model = ElasticNetCV(cv=ps, max_iter=5000, n_jobs=-1, l1_ratio=[.1, .3, .5, .7, .9], \n",
        "                         random_state=42)\n",
        "    model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "    \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=model.predict(X_test_scaled[j,:].reshape(1,-1))\n",
        "        \n",
        "    \n",
        "    return Ypred_test\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   Generalized-linear, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "# Loss ftn : MSE\n",
        "# We use Lasso (Not group Lass) \n",
        "# include spline series of order 2 \n",
        "# number of knots = [3,5,7...] and we choose the only one that minimize cross-validation MSE \n",
        "# we set knots by using linspace(col.mean-2*col.std, col.mean+2*col.std, # knots)\n",
        "# for example if we use 3 knots, the # of variables is 94(order1) + 94*3(order 2) + dummy(74) = 450 \n",
        "\n",
        "def general_linear(X,Y,num_t_v, num_knots):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    from sklearn.linear_model import LassoCV\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "       \n",
        "    mse = np.full((len(num_knots),1),np.nan)\n",
        "    Ypred_test = np.full((len(num_knots),num_test,1),np.nan)\n",
        "    \n",
        "    for i in range(len(num_knots)):\n",
        "        \n",
        "        X_temp = X\n",
        "        \n",
        "        # 94 variables > make spline series of order 2\n",
        "        for j in range(94):\n",
        "            \n",
        "            # make knots\n",
        "            std_train = np.std(X[:num_train,j])\n",
        "            mean_train = np.mean(X[:num_train,j])           \n",
        "            \n",
        "            knots = np.linspace(mean_train-2*std_train, mean_train+2*std_train, num_knots[i])\n",
        "            \n",
        "            # add (variable - knots)**2 column\n",
        "            for k in knots:\n",
        "                add_col = ((X[:,j]-k)**2).reshape(-1,1)\n",
        "                X_temp = np.concatenate((X_temp, add_col), axis=1)\n",
        "        \n",
        "        print(X_temp.shape)\n",
        "        \n",
        "        # Split data into training and test\n",
        "        X_train = X_temp[:(num_train+num_val),:]   # train + validation\n",
        "        Y_train = Y[:(num_train+num_val),:]   # train + validation\n",
        "        \n",
        "        X_test = X_temp[(num_train+num_val):,:]\n",
        "        \n",
        "        # Scale Inputs for Training\n",
        "        X_scaler = StandardScaler()\n",
        "        X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "        \n",
        "        X_test_scaled = X_scaler.transform(X_test)\n",
        "        \n",
        "        # pre-define validation \n",
        "        test_fold =  np.concatenate(((np.full((num_train),-1),np.full((num_val),0))))\n",
        "        ps = PredefinedSplit(test_fold.tolist())\n",
        "        \n",
        "        # we use cross-val to find best 'alpha'(penalty term in loss function)\n",
        "        model = LassoCV(cv=ps, max_iter=3000, n_jobs=-1, random_state=42)\n",
        "        model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "\n",
        "        \n",
        "        # to choose # of knots, calculate mse of validation set\n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0]=model.predict(X_train_scaled[num_train+j,:].reshape(1,-1))\n",
        "            \n",
        "        mse[i,0] = mean_squared_error(Y[num_train:(num_train+num_val),:].reshape(-1), Ypred_val.reshape(-1))\n",
        "        \n",
        "        # predic test set \n",
        "        for j in range(num_test):\n",
        "            Ypred_test[i,j,0]=model.predict(X_test_scaled[j,:].reshape(1,-1))\n",
        "    \n",
        "     \n",
        "    # choose knots that minimize mse in validation\n",
        "    argmin_index = np.argmin(mse)\n",
        "    \n",
        "    print(argmin_index)\n",
        "    \n",
        "    Ypred_test_final = Ypred_test[argmin_index,:,:].reshape(-1,1)\n",
        "    \n",
        "    return Ypred_test_final\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "716cUGgA4r4C"
      },
      "source": [
        "date_col = new_firm_data['DATE']\n",
        "result = Counter(date_col)\n",
        "date = list(result.keys())\n",
        "num = list(result.values())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMA-8o05KHS"
      },
      "source": [
        "#\n",
        "#\n",
        "# X_no_inter (168) : 195703 ~ 201612, y(1) :195704 ~ 201701\n",
        "# X-195703 & y-195704 are in the same row. \n",
        "\n",
        "X_no_inter = new_firm_data.iloc[:,2:170]     # without intersect terms\n",
        "y = new_firm_data.iloc[:,-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91syRvbG5WTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0aaa35-a8ee-4fa4-a739-e6e156c01b2e"
      },
      "source": [
        "y"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         -0.010564\n",
              "1          0.045087\n",
              "2          0.056292\n",
              "3          0.024790\n",
              "4          0.066060\n",
              "             ...   \n",
              "3709904    0.044990\n",
              "3709905    0.017763\n",
              "3709906    0.077129\n",
              "3709907   -0.000419\n",
              "3709908    0.178532\n",
              "Name: excess_return, Length: 3709909, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "eocdX1SJ5WVx",
        "outputId": "b81fe971-6b32-443d-a97d-4a8ca0aed621"
      },
      "source": [
        "X_no_inter # 94 + 74 = 168 "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mvel1</th>\n",
              "      <th>beta</th>\n",
              "      <th>betasq</th>\n",
              "      <th>chmom</th>\n",
              "      <th>dolvol</th>\n",
              "      <th>idiovol</th>\n",
              "      <th>indmom</th>\n",
              "      <th>mom1m</th>\n",
              "      <th>mom6m</th>\n",
              "      <th>mom12m</th>\n",
              "      <th>mom36m</th>\n",
              "      <th>pricedelay</th>\n",
              "      <th>turn</th>\n",
              "      <th>absacc</th>\n",
              "      <th>acc</th>\n",
              "      <th>age</th>\n",
              "      <th>agr</th>\n",
              "      <th>bm</th>\n",
              "      <th>bm_ia</th>\n",
              "      <th>cashdebt</th>\n",
              "      <th>cashpr</th>\n",
              "      <th>cfp</th>\n",
              "      <th>cfp_ia</th>\n",
              "      <th>chatoia</th>\n",
              "      <th>chcsho</th>\n",
              "      <th>chempia</th>\n",
              "      <th>chinv</th>\n",
              "      <th>chpmia</th>\n",
              "      <th>convind</th>\n",
              "      <th>currat</th>\n",
              "      <th>depr</th>\n",
              "      <th>divi</th>\n",
              "      <th>divo</th>\n",
              "      <th>dy</th>\n",
              "      <th>egr</th>\n",
              "      <th>ep</th>\n",
              "      <th>gma</th>\n",
              "      <th>grcapx</th>\n",
              "      <th>grltnoa</th>\n",
              "      <th>herf</th>\n",
              "      <th>...</th>\n",
              "      <th>sic_dummy35</th>\n",
              "      <th>sic_dummy36</th>\n",
              "      <th>sic_dummy37</th>\n",
              "      <th>sic_dummy38</th>\n",
              "      <th>sic_dummy39</th>\n",
              "      <th>sic_dummy40</th>\n",
              "      <th>sic_dummy41</th>\n",
              "      <th>sic_dummy42</th>\n",
              "      <th>sic_dummy43</th>\n",
              "      <th>sic_dummy44</th>\n",
              "      <th>sic_dummy45</th>\n",
              "      <th>sic_dummy46</th>\n",
              "      <th>sic_dummy47</th>\n",
              "      <th>sic_dummy48</th>\n",
              "      <th>sic_dummy49</th>\n",
              "      <th>sic_dummy50</th>\n",
              "      <th>sic_dummy51</th>\n",
              "      <th>sic_dummy52</th>\n",
              "      <th>sic_dummy53</th>\n",
              "      <th>sic_dummy54</th>\n",
              "      <th>sic_dummy55</th>\n",
              "      <th>sic_dummy56</th>\n",
              "      <th>sic_dummy57</th>\n",
              "      <th>sic_dummy58</th>\n",
              "      <th>sic_dummy59</th>\n",
              "      <th>sic_dummy60</th>\n",
              "      <th>sic_dummy61</th>\n",
              "      <th>sic_dummy62</th>\n",
              "      <th>sic_dummy63</th>\n",
              "      <th>sic_dummy64</th>\n",
              "      <th>sic_dummy65</th>\n",
              "      <th>sic_dummy66</th>\n",
              "      <th>sic_dummy67</th>\n",
              "      <th>sic_dummy68</th>\n",
              "      <th>sic_dummy69</th>\n",
              "      <th>sic_dummy70</th>\n",
              "      <th>sic_dummy71</th>\n",
              "      <th>sic_dummy72</th>\n",
              "      <th>sic_dummy73</th>\n",
              "      <th>sic_dummy74</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.630850e+04</td>\n",
              "      <td>1.117907</td>\n",
              "      <td>1.249717</td>\n",
              "      <td>0.134574</td>\n",
              "      <td>10.296745</td>\n",
              "      <td>0.024863</td>\n",
              "      <td>0.059540</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.081150</td>\n",
              "      <td>0.025747</td>\n",
              "      <td>1.078988</td>\n",
              "      <td>-0.023334</td>\n",
              "      <td>0.246223</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.903375e+03</td>\n",
              "      <td>0.331304</td>\n",
              "      <td>0.109762</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>7.032403</td>\n",
              "      <td>0.065248</td>\n",
              "      <td>0.059540</td>\n",
              "      <td>-0.086957</td>\n",
              "      <td>-0.080000</td>\n",
              "      <td>-0.233333</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>-0.219296</td>\n",
              "      <td>0.211836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.841000e+03</td>\n",
              "      <td>0.942052</td>\n",
              "      <td>0.887461</td>\n",
              "      <td>0.058761</td>\n",
              "      <td>7.294037</td>\n",
              "      <td>0.029338</td>\n",
              "      <td>0.059540</td>\n",
              "      <td>-0.037037</td>\n",
              "      <td>-0.005452</td>\n",
              "      <td>-0.105949</td>\n",
              "      <td>0.239950</td>\n",
              "      <td>-0.159943</td>\n",
              "      <td>0.145090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.190100e+04</td>\n",
              "      <td>0.886532</td>\n",
              "      <td>0.785940</td>\n",
              "      <td>-0.032065</td>\n",
              "      <td>9.516942</td>\n",
              "      <td>0.022007</td>\n",
              "      <td>0.059540</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033590</td>\n",
              "      <td>0.101451</td>\n",
              "      <td>0.218003</td>\n",
              "      <td>-0.071187</td>\n",
              "      <td>0.285833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.525000e+04</td>\n",
              "      <td>1.229520</td>\n",
              "      <td>1.511719</td>\n",
              "      <td>-0.102811</td>\n",
              "      <td>8.421013</td>\n",
              "      <td>0.025453</td>\n",
              "      <td>0.059540</td>\n",
              "      <td>-0.030717</td>\n",
              "      <td>0.048778</td>\n",
              "      <td>0.173976</td>\n",
              "      <td>1.174509</td>\n",
              "      <td>-0.036405</td>\n",
              "      <td>0.104000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709904</th>\n",
              "      <td>1.577480e+06</td>\n",
              "      <td>1.013563</td>\n",
              "      <td>1.027309</td>\n",
              "      <td>-0.277860</td>\n",
              "      <td>15.206151</td>\n",
              "      <td>0.041732</td>\n",
              "      <td>0.125907</td>\n",
              "      <td>0.127503</td>\n",
              "      <td>0.069296</td>\n",
              "      <td>0.586293</td>\n",
              "      <td>0.208586</td>\n",
              "      <td>0.031465</td>\n",
              "      <td>2.925487</td>\n",
              "      <td>0.014530</td>\n",
              "      <td>-0.014530</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.191205</td>\n",
              "      <td>0.562758</td>\n",
              "      <td>-1.846831</td>\n",
              "      <td>0.341639</td>\n",
              "      <td>-0.016609</td>\n",
              "      <td>0.079290</td>\n",
              "      <td>0.050859</td>\n",
              "      <td>-0.040048</td>\n",
              "      <td>0.008107</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>0.009770</td>\n",
              "      <td>0.051764</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.911046</td>\n",
              "      <td>0.092049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.122080</td>\n",
              "      <td>0.065750</td>\n",
              "      <td>0.178405</td>\n",
              "      <td>3.762161</td>\n",
              "      <td>0.091522</td>\n",
              "      <td>0.073614</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709905</th>\n",
              "      <td>1.250976e+06</td>\n",
              "      <td>1.595315</td>\n",
              "      <td>2.545028</td>\n",
              "      <td>-0.137348</td>\n",
              "      <td>14.916210</td>\n",
              "      <td>0.043201</td>\n",
              "      <td>0.016401</td>\n",
              "      <td>-0.001203</td>\n",
              "      <td>-0.047018</td>\n",
              "      <td>0.037972</td>\n",
              "      <td>0.506586</td>\n",
              "      <td>-0.000314</td>\n",
              "      <td>2.258305</td>\n",
              "      <td>0.085975</td>\n",
              "      <td>-0.085975</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.330296</td>\n",
              "      <td>0.252853</td>\n",
              "      <td>-0.166734</td>\n",
              "      <td>0.065594</td>\n",
              "      <td>2.513108</td>\n",
              "      <td>0.043555</td>\n",
              "      <td>-0.002498</td>\n",
              "      <td>0.024946</td>\n",
              "      <td>0.004733</td>\n",
              "      <td>0.092304</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115472</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.735153</td>\n",
              "      <td>0.934244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.167011</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.492449</td>\n",
              "      <td>1.224218</td>\n",
              "      <td>0.064913</td>\n",
              "      <td>0.031524</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709906</th>\n",
              "      <td>5.600536e+06</td>\n",
              "      <td>0.298267</td>\n",
              "      <td>0.088963</td>\n",
              "      <td>0.206434</td>\n",
              "      <td>16.319191</td>\n",
              "      <td>0.026198</td>\n",
              "      <td>-0.071728</td>\n",
              "      <td>0.093973</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>-0.112178</td>\n",
              "      <td>0.429553</td>\n",
              "      <td>-0.050955</td>\n",
              "      <td>2.355625</td>\n",
              "      <td>0.104737</td>\n",
              "      <td>-0.104737</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.002310</td>\n",
              "      <td>0.049733</td>\n",
              "      <td>-0.560291</td>\n",
              "      <td>1.580322</td>\n",
              "      <td>48.338806</td>\n",
              "      <td>0.046039</td>\n",
              "      <td>-0.063371</td>\n",
              "      <td>0.250537</td>\n",
              "      <td>-0.024074</td>\n",
              "      <td>-0.001802</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.758463</td>\n",
              "      <td>0.708919</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013783</td>\n",
              "      <td>0.038302</td>\n",
              "      <td>0.038483</td>\n",
              "      <td>0.953897</td>\n",
              "      <td>0.372022</td>\n",
              "      <td>0.037375</td>\n",
              "      <td>0.065747</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709907</th>\n",
              "      <td>8.573280e+04</td>\n",
              "      <td>0.628519</td>\n",
              "      <td>0.395036</td>\n",
              "      <td>0.020854</td>\n",
              "      <td>10.862196</td>\n",
              "      <td>0.059797</td>\n",
              "      <td>0.015187</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.147727</td>\n",
              "      <td>-0.233449</td>\n",
              "      <td>-0.029555</td>\n",
              "      <td>0.550716</td>\n",
              "      <td>0.134906</td>\n",
              "      <td>-0.134906</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.370022</td>\n",
              "      <td>0.837790</td>\n",
              "      <td>0.098907</td>\n",
              "      <td>-0.018161</td>\n",
              "      <td>-10.531395</td>\n",
              "      <td>0.169262</td>\n",
              "      <td>0.351403</td>\n",
              "      <td>0.137229</td>\n",
              "      <td>0.155842</td>\n",
              "      <td>0.795305</td>\n",
              "      <td>-0.028000</td>\n",
              "      <td>-0.291295</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.338622</td>\n",
              "      <td>0.189945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007027</td>\n",
              "      <td>-0.048176</td>\n",
              "      <td>0.188891</td>\n",
              "      <td>-0.793772</td>\n",
              "      <td>0.243760</td>\n",
              "      <td>0.575073</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709908</th>\n",
              "      <td>2.840318e+07</td>\n",
              "      <td>1.588092</td>\n",
              "      <td>2.522036</td>\n",
              "      <td>-0.121017</td>\n",
              "      <td>18.580862</td>\n",
              "      <td>0.049922</td>\n",
              "      <td>0.024821</td>\n",
              "      <td>-0.042128</td>\n",
              "      <td>-0.114232</td>\n",
              "      <td>-0.141275</td>\n",
              "      <td>0.809082</td>\n",
              "      <td>0.138951</td>\n",
              "      <td>5.819348</td>\n",
              "      <td>0.052241</td>\n",
              "      <td>-0.052241</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.383504</td>\n",
              "      <td>0.034522</td>\n",
              "      <td>-0.469607</td>\n",
              "      <td>-0.078723</td>\n",
              "      <td>20.902399</td>\n",
              "      <td>-0.016628</td>\n",
              "      <td>-0.129942</td>\n",
              "      <td>-0.146451</td>\n",
              "      <td>0.045645</td>\n",
              "      <td>0.258677</td>\n",
              "      <td>0.046503</td>\n",
              "      <td>-0.128691</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.991227</td>\n",
              "      <td>0.081350</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.194397</td>\n",
              "      <td>-0.028173</td>\n",
              "      <td>0.230131</td>\n",
              "      <td>5.187364</td>\n",
              "      <td>0.037375</td>\n",
              "      <td>0.087293</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3709909 rows  168 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                mvel1      beta  ...  sic_dummy73  sic_dummy74\n",
              "0        8.630850e+04  1.117907  ...            0            0\n",
              "1        3.903375e+03  0.331304  ...            0            0\n",
              "2        9.841000e+03  0.942052  ...            0            0\n",
              "3        5.190100e+04  0.886532  ...            0            0\n",
              "4        3.525000e+04  1.229520  ...            0            0\n",
              "...               ...       ...  ...          ...          ...\n",
              "3709904  1.577480e+06  1.013563  ...            0            0\n",
              "3709905  1.250976e+06  1.595315  ...            1            0\n",
              "3709906  5.600536e+06  0.298267  ...            0            0\n",
              "3709907  8.573280e+04  0.628519  ...            0            0\n",
              "3709908  2.840318e+07  1.588092  ...            0            0\n",
              "\n",
              "[3709909 rows x 168 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgZby-t5fbK"
      },
      "source": [
        "\n",
        "num_est = 1  # We estimate parameter 1 time, here not use\n",
        "\n",
        "# if we estimate parameters more than 1 time(i.e using longer data), we should set below # recursively\n",
        "# Train \n",
        "# Validation \n",
        "# Test \n",
        "num_train = sum(num[0:216])\n",
        "num_val = sum(num[216:(216+144)])\n",
        "num_test = sum(num[(216+144):])\n",
        "num_t_v = [num_train, num_val]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiK2HFY03BFd"
      },
      "source": [
        "\n",
        "y_true = y.iloc[-num_test:].to_numpy().reshape(-1,1)  # for caluclating R2oos\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxcaHYHS3BDE"
      },
      "source": [
        "\n",
        "# Computational Ressources: Determine Number of available cores\n",
        "ncpus = mp.cpu_count()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUgJ6RkD3A1q",
        "outputId": "b4c55694-0f01-44c2-e949-8df5ea813c0e"
      },
      "source": [
        "print(\"CPU count is: \"+str(ncpus))\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU count is: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s45KuUSF4VEh",
        "outputId": "5d218a75-e970-4697-f63f-528278e88563"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train_ols = X_no_inter.iloc[:(num_train+num_val),:].to_numpy()\n",
        "y_train_ols = y.iloc[:(num_train+num_val)].to_numpy()\n",
        "\n",
        "reg = LinearRegression().fit(X_train_ols, y_train_ols)\n",
        "\n",
        "Y_pred_ols = np.full((num_test,1),np.nan, dtype = np.float32 )\n",
        "\n",
        "for i in range(num_test):\n",
        "    Y_pred_ols[i,0] = reg.predict(X_no_inter.iloc[(num_train+num_val+i),:].to_numpy().reshape(1,-1))\n",
        "    \n",
        "print('R2OOS, MSE error - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols))    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, MSE error - Linear regression without intersection terms :  -0.07232272624969482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj8uCxLKCJ-B",
        "outputId": "77d9af90-3f60-472b-af6f-88d4f19c9c46"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2460194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnlKgsBI4VG4",
        "outputId": "50cd093a-7c3c-40eb-bbdf-a0df6735c2e9"
      },
      "source": [
        "\n",
        "\n",
        "# ===========================================================================\n",
        "#     OLS, Loss: Huber Loss, 94 + dummy variable(no intersection term)\n",
        "# ===========================================================================\n",
        "\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "reg_huber = HuberRegressor(max_iter=500, alpha=0).fit(X_train_ols, y_train_ols)\n",
        "\n",
        "Y_pred_ols_huber = np.full((num_test,1),np.nan, dtype = np.float32 )\n",
        "\n",
        "for i in range(num_test):\n",
        "    Y_pred_ols_huber[i,0] = reg_huber.predict(X_no_inter.iloc[(num_train+num_val+i),:].to_numpy().reshape(1,-1))\n",
        "\n",
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols_huber))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  -0.09587621688842773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWMrp_IG4VJX",
        "outputId": "f20833e3-6285-4258-b85a-d4a65dd75c0c"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================================================\n",
        "#    PCR, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components\n",
        "# ===========================================================================\n",
        "\n",
        "numpc = [3,6,9,12,15,20,25,30]\n",
        "\n",
        "\n",
        "Y_pred_pca, argmin_numpc = FL.Pca_regression(X_no_inter.to_numpy(), y.to_numpy().reshape(-1,1), numpc, num_t_v)\n",
        "\n",
        "print('R2OOS, Principal Components Regression - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pca)) \n",
        "print('# of principal components : ', argmin_numpc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Principal Components Regression - without intersection terms :  -197.13214111328125\n",
            "# of principal components :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOBlr8PA4VP0",
        "outputId": "674fa9e3-6bc7-4aa9-f17b-abe7b115a96f"
      },
      "source": [
        "y_true"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.06709452],\n",
              "       [-0.04381052],\n",
              "       [ 0.00511448],\n",
              "       ...,\n",
              "       [ 0.07712882],\n",
              "       [-0.00041918],\n",
              "       [ 0.17853181]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIpulOj3I04w",
        "outputId": "c331966c-0d6e-42af-b39a-c0b9077c3e83"
      },
      "source": [
        "Y_pred_ols_huber"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00186346],\n",
              "       [0.00918638],\n",
              "       [0.00198924],\n",
              "       ...,\n",
              "       [0.07238867],\n",
              "       [0.05319119],\n",
              "       [0.04173381]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUKy_GRHI70w",
        "outputId": "ac46b1b3-d202-4677-d02e-e30c741d35b6"
      },
      "source": [
        "Y_pred_pca"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01218863],\n",
              "       [-0.00974452],\n",
              "       [-0.0098946 ],\n",
              "       ...,\n",
              "       [-0.03729808],\n",
              "       [-0.02907982],\n",
              "       [-0.01334786]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCX4TQbfJfeD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnjnEOPvJfgm",
        "outputId": "3f42f72c-a097-4e25-87ef-e1fe1dfe0663"
      },
      "source": [
        "\n",
        "# ===========================================================================\n",
        "#    PLS, 94 + dummy variable(no intersection term), Use cross-validation to select the number of components\n",
        "# ===========================================================================\n",
        "\n",
        "numpls = [3,6,9,12,15,20,25,30]\n",
        "\n",
        "Y_pred_pls, argmin_numpls = FL.Pls_regression(X_no_inter.to_numpy(), y.to_numpy().reshape(-1,1), numpls, num_t_v)\n",
        "\n",
        "print('R2OOS, Partial Least Square - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pls)) \n",
        "print('# of components : ', argmin_numpls)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Partial Least Square - without intersection terms :  -112122.67221118104\n",
            "# of components :  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p46nmR_6JfjO",
        "outputId": "47446014-5798-4581-a05d-a67e6eebe4cb"
      },
      "source": [
        "Y_pred_pls"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.09239537],\n",
              "       [ 0.12443741],\n",
              "       [ 0.11558041],\n",
              "       ...,\n",
              "       [ 0.0182573 ],\n",
              "       [ 0.81252609],\n",
              "       [-0.00791839]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MO5Bx2NJflp",
        "outputId": "38190b67-8699-4508-fb8a-77e62d9b0997"
      },
      "source": [
        "\n",
        "# =========================================================================\n",
        "#  elastic-net, Loss : mse + penalty, 94 + dummy variable(no intersection term), hyperparameter tuning\n",
        "# =========================================================================\n",
        "\n",
        "Y_pred_elastic = FL.elastic_net(X_no_inter.to_numpy(), y.to_numpy().reshape(-1,1), num_t_v)\n",
        "\n",
        "print('R2OOS, Elastic-net - without intersection terms : ', FL.R2OOS(y_true, Y_pred_elastic))\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Elastic-net - without intersection terms :  0.0014715596401045916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMH28UwfPNRK",
        "outputId": "6f0d6722-253f-428c-b341-2952fc47f81c"
      },
      "source": [
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   Generalized-linear, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "# Loss ftn : MSE\n",
        "# We use Lasso (Not group Lass) \n",
        "# include spline series of order 2 \n",
        "# number of knots = [3,5,7...] and we choose the only one that minimize cross-validation MSE \n",
        "# we set knots by using linspace(col.mean-2*col.std, col.mean+2*col.std, # knots)\n",
        "# for example if we use 3 knots, the # of variables is 94(order1) + 94*3(order 2) + dummy(74) = 450 \n",
        "\n",
        "num_knots = [3]\n",
        "\n",
        "Y_pred_general_lin = FL.general_linear(X_no_inter.to_numpy(), y.to_numpy().reshape(-1,1), num_t_v, num_knots)\n",
        "\n",
        "print('R2OOS, generalized linear - without intersection terms / with knots : ', FL.R2OOS(y_true, Y_pred_general_lin))\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3709909, 450)\n",
            "0\n",
            "R2OOS, generalized linear - without intersection terms / with knots :  0.0014715596401045916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWm8T6pqTW_1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz7itnIQTXC6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRWkbWYURdL5",
        "outputId": "3c38a37f-5dc6-4115-ebac-583d9474f3d6"
      },
      "source": [
        "Y_pred_general_lin"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00768697],\n",
              "       [0.00768697],\n",
              "       [0.00768697],\n",
              "       ...,\n",
              "       [0.00768697],\n",
              "       [0.00768697],\n",
              "       [0.00768697]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_FuoPM5RgCH",
        "outputId": "7866571f-7562-4ab9-eef7-108c3c9a38aa"
      },
      "source": [
        "Y_pred_elastic"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00768697],\n",
              "       [0.00768697],\n",
              "       [0.00768697],\n",
              "       ...,\n",
              "       [0.00768697],\n",
              "       [0.00768697],\n",
              "       [0.00768697]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKD4q-ifSxwQ",
        "outputId": "52bc05cc-0896-49ec-b407-15bf7f36f7ca"
      },
      "source": [
        "num_t_v"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[482374, 767341]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlPjJ_3MTXzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-0jzlSOTX1N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hNlCJwMTX38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKbhSPd2TX6D",
        "outputId": "581c2086-1b82-4faf-89a5-c94ea0b9dc21"
      },
      "source": [
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols_huber))\n",
        "print('R2OOS, Partial Least Square - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pls)) \n",
        "print('R2OOS, Elastic-net - without intersection terms : ', FL.R2OOS(y_true, Y_pred_elastic))\n",
        "print('R2OOS, generalized linear - without intersection terms / with knots : ', FL.R2OOS(y_true, Y_pred_general_lin))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  -0.09587621688842773\n",
            "R2OOS, Partial Least Square - without intersection terms :  -112122.67221118104\n",
            "R2OOS, Elastic-net - without intersection terms :  0.0014715596401045916\n",
            "R2OOS, generalized linear - without intersection terms / with knots :  0.0014715596401045916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg6n-9XHTX8D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}